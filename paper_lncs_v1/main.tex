\documentclass[runningheads]{llncs}
\usepackage{pgfplots}
\usepackage{amsmath,amssymb}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{listings}
\usepackage{courier}
\pgfplotsset{compat=1.18}

% 统一柱状图样式
\pgfplotsset{
  archebar/.style={
    ybar,
    bar width=8pt,
    enlarge x limits=0.2,
    legend style={
      at={(0.5,1.02)},
      anchor=south,
      legend columns=-1,
      /tikz/every even column/.append style={column sep=4pt}
    },
    ymin=0, ymax=1.05,
    axis x line*=left,
    axis y line*=left,
    tick align=outside,
    tick style={semithick},
    label style={font=\small},
    tick label style={font=\small},
    title style={font=\small},
    major grid style={dashed, gray!40},
    ymajorgrids=true
  }
}


\usepackage{graphicx}
\usepackage{url}

\title{ArcheRisk-Core: A Micro-Benchmark MAS Security Evaluation Based On Behaviour Archetype and Topology}
\titlerunning{ArcheRisk-Core: LLM Agent Archetype $\times$ Topology Micro-Benchmark}


\author{Anonymous Submission}
\institute{Organization Withheld for Double-Blind Review}

\begin{document}
\maketitle

\begin{abstract}
As the adoption of Large Language Models (LLMs) in Multi-Agent Systems (MAS) continues to expand, security issues have become increasingly prominent. However, existing research has focused mainly on the complex attack and defence scenarios of the MAS pipeline, lacking a systematic analysis of how the underlying risk factors (such as archetypes and topological constraints) affect failure dynamics. To address these limitations, we propose ArcheRisk-Core --- a LLM MAS micro-benchmark that focuses on evaluating the interaction effects of behaviour prototypes and topology configurations. ArcheRisk-Core constructs a controllable evaluation environment using five types of behaviour prototypes (manipulator, covert actor, deceiver, infiltrator escalator, mixed) and two types of topology configurations (secure, defended) and records the dynamic performance of the agent in the three stages of “behaviour deviation → information leakage → state destruction” using a standardised Episode Schema. ArcheRisk-Core supports large-scale, fully reproducible MAS security experiments. In this study, we evaluate a representative dataset of 2,000 episodes, revealing how behavioural dynamics and topological constraints jointly influence three key security indicators: attack success rate, leak rate, and unauthorised write rate. Experiments have shown that explicit inducible attacks (manipulator, deceiver, infiltrator escalator) are easily suppressed in defended configurations, while covert infiltration attacks (covert actor, mixed) maintain high stability in both topology configurations. The goal of ArcheRisk-Core is not to simulate a complete MAS, but to provide a reproducible, scalable, and factor controllable micro benchmark, laying the foundation for future MAS security testing, risk modelling, and multi-hop interaction research.

Large language model (LLM) multi-agent systems can fail in security-critical ways because roles are separated, messages propagate across agents, and tool use expands the attack surface. We present ArcheRisk-Core, a controlled benchmark that isolates two factors: attacker messaging behaviours and the agents’ communication topology, under a minimal planner–worker–reviewer workflow. In each episode, an adversary injects a single natural-language message to the Worker, and we log the full multi-turn trace. We score three outcomes: task deviation, secret leakage, and unauthorised tool writes to protected resources, detected in a sandboxed environment. Across attacker behaviours and system configurations, we find that basic static defences substantially reduce overt inducement attacks, while covert infiltration strategies remain resilient and frequently trigger unauthorised tool actions. ArcheRisk-Core provides an extensible, reproducible basis for factor-level MAS security evaluation and comparison of defence designs.


\keywords{Multi-Agent Systems \and LLM Security \and Behaviour Archetypes \and Topology-Aware Risk Modelling \and Attack Dynamics \and Information Leakage \and Unauthorised Write \and Security Benchmarking \and Adaptive Defence}
\end{abstract}

\section{Introduction}
With the increasing application of LLM in autonomous collaboration, task planning, and decision support, LLM-based multi-agent systems (LLM MAS) have emerged as a promising paradigm for collaborative reasoning and autonomous coordination across complex tasks~\cite{Wooldridge2009,Busoniu2008,Guo2024LLMASurvey}. Despite rapid development in this field, security research on MAS remains an early stage and lacks a factor-level understanding of how risks arise and propagate within agent interactions.~\cite{maoyuan2025agentsafe}. Currently, most MAS security research typically focuses on complete systems, such as multi-turn dialogues~\cite{Mei2025ContextEngineeringSurvey}, tool-augmented planners~\cite{Shen2024MMCLA}, or role-based collaboration~\cite{Zhang2025MaAS}. While these studies reflect real-world use cases, they suffer from several core limitations.
First, the inherent complexity of multi-agent systems involve numerous roles, intertwined message flows, and tool invocations. The absence of factor-level decomposition makes it difficult to disentangle
behavioural drivers from structural constraints.~\cite{Sharma2025UMSB}.
Second, the absence of controllable variables prevents researchers from isolating the independent contributions of behavioural archetypes and topology configurations to system degradation~\cite{maoyuan2025agentsafe}.
Finally, the engineering overhead of constructing realistic MAS environments makes systematic, large-scale experimentation difficult~\cite{Sharma2025UMSB}.

In this context, we propose ArcheRisk-Core: a factorised micro benchmark for studying the risk generation mechanism of LLM agents. The core design concept is that the security risks of complex MAS stem from a combination of several fundamental factors: behaviour archetype × propagation dynamics × topology constraints. Unlike directly building a complete MAS benchmark, ArcheRisk-Core adopts a minimised three-role abstraction (planner → worker → reviewer) and only retains two types of controllable topology configurations (secure vs defended). In a streamlined but strictly controllable environment, it focuses on examining how different behavioural prototypes drive successful attacks, leaks, and state destruction. and how simple topology/defence configurations can amplify or suppress these behavioural effects. This basic layer micro-benchmark brings three advantages: it is factor-controllable, highly reproducible, and naturally scalable. ArcheRisk-Core does not aim to simulate complete MAS systems, but instead provides a lightweight, factor-controllable benchmark that isolates key drivers of system-level risk. It offers a reproducible foundation for advancing scalable evaluations and cross-framework comparisons in MAS security research. 
We make the following contributions: 
\begin{itemize}[topsep=1pt, itemsep=0pt]
    \item We propose a factorised risk modelling framework with five behavioural prototypes and two topology configurations, encoding key stages into an Episode Schema.
    \item We build a reproducible LLM agent micro benchmark with an evaluation pipeline and systematic analysis.
    \item We establish the foundational layer for MAS-scale security research, allowing extensions to more complex MAS environments.
    \item We alleviate the long-standing difficulty of performing systematic and reproducible MAS security evaluations at the factor level by reducing a complex multi-agent ecosystem into a minimal, controllable micro-benchmark where risk factors can be independently manipulated and empirically analysed.
\end{itemize}

\section{Related Work}
This section reviews three directions most closely related to ArcheRisk-Core:
(1) LLM security evaluation; (2) MAS framework and security research; (3) Behavioural attacks and risk propagation mechanisms. These works collectively constitute the research background of ArcheRisk-Core. 

\subsection{LLM Security Evaluation}
Existing security evaluation frameworks such as RAS-EVAL~\cite{rasEval2025}, Red Teaming LLMs~\cite{redTeamLLMs2025}, and SafetyBench~\cite{safetyBench2023} primarily assess the single-agent input–output robustness. These evaluations typically examine whether a model rejects adversarial prompts, prevents malicious content induction, or avoids harmful output generation. These frameworks reveal the vulnerability of LLM in scenarios such as direct prompting, context poisoning, and instruction obfuscation, but present two key limitations. First, without involving multiple rounds of interaction and agent collaboration, single-model I/O cannot capture MAS-specific risks such as agent propagation and misleading amplification effects; Second, unable to observe the state changes of the model in the decision chain/communication flow, as single-agent evaluation only looks at the final output while MAS risks often occur in the intermediate states (reasoning drift). In contrast, ArcheRisk-Core is not a \textbf{capability assessment} of a single LLM, but rather a characterisation of the security degradation of agent behaviour under different topological conditions. It studies how behavioural archetypes and topological constraints collectively shape system risk.

\subsection{MAS Frameworks and Security}
Classic multi-agent frameworks include AutoGen~\cite{autoGen2023}, ChatDev~\cite{chatDev2023}, CAMEL~\cite{camel2022}, etc., which support workflows composed of multiple agents, such as Planner–Worker–Reviewer, Coder–Tester–Designer, and other structures. Recent work has begun exploring MAS security threats from multiple angles. Some studies focus on malicious prompt injection using optimization-based methods~\cite{Yu2025CODES} or graph-aware distribution strategies~\cite{Khan2025Agents}. Others explore stealthy inter-agent tampering via message manipulation~\cite{Yan2025MAST} or Agent-in-the-Middle attacks~\cite{He2025RedTeam}. Additional threats include information leakage~\cite{Wang2025IP}, link-based phishing~\cite{Kong2025WebFraud}, and coordinated jailbreak amplification~\cite{Qi2025Amplified}.
In terms of defence, researchers have proposed topology-aware anomaly detection using GNNs~\cite{Wang2025GSafeguard}, unsupervised pattern modelling via contrastive learning~\cite{Miao2025BlindGuard}, and agent-based prompt filtering systems~\cite{Zeng2024AutoDefense}. Broader surveys address MAS-specific security risks~\cite{Ko2025SevenChallenges}, trust and risk frameworks~\cite{Raza2025TRiSM}, and zero-trust architectures for edge-agentic systems~\cite{Liu2025Secure}.
But these MAS security studies rely on fixed workflows, static agent roles, and rigid topologies. This makes it difficult to isolate the independent effects of each risk factor, since agent behaviours and network structure vary only together. As a result, these evaluations resemble one-off system demonstrations rather than general benchmarks. ArcheRisk-Core is designed to fill this gap. It provides a controllable, structured micro-benchmark that is role-aware and topology-aware, so each behavioural archetype and network configuration can be manipulated independently.

\subsection{Behavioural Attacks and Risk Propagation}
Prior studies have shown that single-agent LLMs can be hijacked by prompt injections and stealthy instruction propagation~\cite{IPIDefense2025}. In MAS, such attacks can be amplified through inter-agent communication. For example, MAST~\cite{Yan2025MAST} proposed a multi-round adaptive stealthy tampering framework that intercepts messages between agents to manipulate system behaviour over time; MASLEAK~\cite{Wang2025IP} mimics computer worms, using cascading queries to propagate hidden instructions through agent chains and leak system prompts layer-by-layer.
These studies show that misleading information can be exponentially amplified in chain-of-thought collaborations, and attackers can gradually shift an agent’s self-role understanding (\textbf{role drift}), leading to unauthorised system-level behaviours. Related research has demonstrated viral prompt infection and the stealth propagation of encoded instructions between agents~\cite{Wang2025IP}. However, most of these works lack a unified methodology: they do not model behavioural archetypes structurally, omit topology as a controllable variable, and do not offer reproducible datasets or comparable evaluation metrics. Therefore, standardised micro-benchmarks like ArcheRisk-Core are needed to systematically study these threats.

\section{Problem Statement}
LLM-driven multi-agent systems (MAS) present significant system-level security risks in open environments~\cite{Ko2025SevenChallenges}. Unlike isolated LLMs, MAS vulnerabilities arise from their networked nature. In particular, adversarial effects can propagate across agents (errors amplifying through multi-hop interactions), and network topology can exacerbate risk (attacks targeting highly-connected hub agents may have disproportionate impact). Moreover, different attack modes (e.g., behavioural induction vs. covert infiltration) lead to distinct propagation patterns~\cite{Ko2025SevenChallenges}. Indeed, prior work notes the absence of standardised benchmarks for evaluating LLM MAS’ security in dynamic settings. Two major challenges hinder systematic study: real-world MAS involves many interacting variables which makes causal attribution difficult, and reproducing large-scale MAS experiments can be prohibitively costly~\cite{rasEval2025}.

\subsection{Core Issues}
Based on these challenges, We therefore formulate our core research question as: How do combinations of agent behavioural archetype and network topology affect attack success, sensitive-information leakage, and unauthorised state modifications within a simplified LLM-agent chain? This focuses on the underlying factor layer of MAS risk. The behavioural factor is the attack mode, the topology factor is the constrained mode (secure vs defended), and the output factors are behaviour deviation, leakage, and state destruction.

\subsection{ABeRT Framework}
We use the ABeRT (Agent Behaviour–Risk Interaction–Topology) three-layer framework to describe the MAS degradation process under attack. As shown in Fig.1, the behaviour layer focuses on when an agent’s decisions deviate abnormally; the risk interaction layer describes how these biases are amplified and propagated through agent communication; the topology layer examines how collaborative network structures evolve or collapse (e.g., key node failures, information flow tampering). With ABeRT, we can define different attack and defence scenarios and measurement indicators to comprehensively record the MAS evolution from local instability to system disintegration. Fig.1 illustrates this framework. However, modelling all three layers at once can be difficult to reproduce. Therefore, ArcheRisk-Core focuses on the interaction effects between the behaviour and topology layers of ABeRT: how different behavioural archetypes drive attack success, leakage, and writing under different topology configuration conditions. This preserves the core structure of MAS security while avoiding real MAS engineering noise.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{Figure1.png} 
    \caption{ABeRT Framework (Agent Behaviour – Risk Interaction – Topology)}
    \label{fig:ABeRT}
\end{figure}

\section{Methodology}
This section presents the core methodology of ArcheRisk-Core, consisting of four components: behaviour archetypes, topology configurations, the episode schema, and security metrics. The core assumption is that MAS risks are collectively determined by behaviour archetype, transmission dynamics and topology structure. Accordingly, an effective MAS security benchmark must model both behaviour and topology and provide reproducible quantitative measurements. Our objective is to build a reproducible, quantifiable, and scalable micro-benchmark that measures how attack performance varies across archetypes and topology configurations within a minimal agent execution chain.

\subsection{Threat Model}
\label{subsec:threat-model}

To support the factorised micro-benchmark introduced above, we define a bounded and reproducible threat model that specifies the attacker's capabilities, visibility, goals, and constraints within ArcheRisk-Core's minimal three-role execution chain. The formulation follows standard security-analysis practice, emphasising explicit attacker capabilities and constrained attack surfaces, consistent with evaluation methodologies used in recent LLM and MAS security studies~\cite{safetyBench2023,rasEval2025,Wang2025IP}.

\subsubsection*{Entities}
\medskip
ArcheRisk-Core operates on a fixed chain of three agent roles:
\begin{itemize}
  \item \textbf{Planner} $P$: produces the structured task plan.
  \item \textbf{Worker} $W$: performs the main reasoning step and is the primary target of adversarial influence.
  \item \textbf{Reviewer} $R$: validates or critiques the worker's output.
  \item \textbf{Attacker} $\mathcal{A}$: instantiated as one of the behavioural archetypes defined in Section~\ref{sec:behaviour-archetypes}.
  \item \textbf{Topology configuration} $T \in \{\mathit{insecure}, \mathit{defended}\}$: a defence-inspired configuration rather than a MAS communication graph, consistent with topology-controlled evaluation approaches in MAS security research~\cite{maoyuan2025agentsafe,Sharma2025UMSB,ASB2024}.
\end{itemize}

Each evaluation episode follows the deterministic sequence $P \rightarrow W \rightarrow R$, as defined in the episode schema presented later in this section.

\subsubsection*{Attacker Capabilities}

The attacker $\mathcal{A}$ has bounded capabilities:
\begin{enumerate}
  \item It injects exactly one adversarial natural-language message into the worker's input channel in each episode.
  \item It cannot modify system prompts, role definitions, or internal states of any agent.
  \item It cannot alter the pipeline structure, add extra message hops, or invoke external tools.
  \item It operates purely through natural-language instructions, consistent with behaviour-level adversaries in prompt-based attack research~\cite{Yan2025MAST,Khan2025Agents}.
\end{enumerate}

\subsubsection*{Attacker Visibility}

The attacker operates under partial observability:
\begin{itemize}
  \item It can observe the worker's previous output $o_W$.
  \item It cannot observe the planner's internal plan, the reviewer's internal reasoning, any system prompts, or the active topology configuration $T$.
\end{itemize}
This corresponds to black-box adversarial settings commonly adopted in LLM agent-evaluation pipelines~\cite{Wang2025IP,He2025RedTeam}.

\subsubsection*{Goals}

The attacker aims to trigger one or more measurable failure events defined in the episode schema:
\begin{enumerate}
  \item \textbf{Attack success (ASR)}: the worker's output deviates from the intended task.
  \item \textbf{Leakage (LR)}: the episode emits protected information such as a \texttt{SECRET\_TOKEN}.
  \item \textbf{Unauthorised write (UWR)}: the agent attempts to write malicious content to a protected resource.
\end{enumerate}

These three categories correspond to behaviour deviation, data leakage, and state corruption—recurring failure modes observed in multi-agent security studies~\cite{Ko2025SevenChallenges,Wang2025IP}.

Let $\mathcal{S}_{\text{success}}$ denote the set of episodes in which at least one of these events occurs.

\subsubsection*{Constraints}

To maintain reproducibility and isolate behaviour–topology interactions, we impose the following constraints:
\begin{itemize}
  \item Exactly one adversarial injection per episode.
  \item A fixed three-role agent chain; multi-hop propagation is not modelled.
  \item The topology configuration $T$ is static for each episode.
  \item All interactions occur through the natural-language interface.
  \item All outcomes must be representable under the episode schema in Section~\ref{sec:episode-schema}.
\end{itemize}

\subsubsection*{Topology / Defence Configuration}

ArcheRisk-Core defines two topology-inspired configurations:
\begin{description}
  \item[\emph{Insecure}] No role-boundary checks, no redaction, and no safety filters.
  \item[\emph{Defended}] Includes static defence modules: role-boundary constraints, redaction filters, consistency checks, and write filters.
\end{description}

These configurations approximate different security surfaces and enable controlled experiments on how structural defences interact with behavioural archetypes, following topology-guided analysis approaches in MAS security~\cite{Wang2025GSafeguard,Sharma2025UMSB}.

\subsubsection*{Formalised Threat Model}

Let
\begin{itemize}
  \item $\mathcal{A}$ be an attacker strategy corresponding to a behavioural archetype,
  \item $T \in \{\mathit{insecure}, \mathit{defended}\}$ be the topology configuration,
  \item $E \sim \mathcal{D}$ be an episode sampled from the benchmark distribution,
  \item $R(E; \mathcal{A}, T) = (\mathrm{ASR}, \mathrm{LR}, \mathrm{UWR})$ be the risk vector for that episode.
\end{itemize}

We define the adversarial advantage under configuration $T$ as
\[
\mathrm{Adv}(\mathcal{A}, T)
 = \Pr_{E \sim \mathcal{D}}\big[\,R(E; \mathcal{A}, T) \in \mathcal{S}_{\text{success}}\,\big].
\]

For each metric $m \in \{\mathrm{ASR}, \mathrm{LR}, \mathrm{UWR}\}$, its expected value is
\[
\mathrm{Adv}_{m}(\mathcal{A}, T)
 = \mathbb{E}_{E \sim \mathcal{D}}\big[\,R_{m}(E; \mathcal{A}, T)\big].
\]

In particular, the attack success rate is:
\[
\mathrm{ASR}(\mathcal{A}, T)
 = \mathbb{E}_{E \sim \mathcal{D}}\left[
   \mathbb{1}\big(\text{worker\_output deviates from task}\big)
 \right].
\]

This formalisation makes attacker behaviour, topology configuration, and risk metrics mathematically explicit, and provides a threat model aligned with the micro-benchmark nature of ArcheRisk-Core, as emphasised in recent LLM and MAS security evaluation frameworks~\cite{rasEval2025,Sharma2025UMSB}.


\subsection{Behaviour Archetypes}
\label{sec:behaviour-archetypes}
ArcheRisk-Core abstracts attack behaviours into five archetypes: 
\begin{itemize}[topsep=1pt, itemsep=0pt]
    \item \textbf{Manipulator}: a strong inducer that directly prompts the agent to leak sensitive information.
    \item \textbf{Covert Actor}: a concealed write type that emphasises stealthiness.
    \item \textbf{Deceiver}: constructs false context to induce incorrect conclusions.
    \item \textbf{Infiltrator Escalator}: gradually affects the inference chain to achieve permission escalation.
    \item \textbf{Mixed}: a combination of multiple types of attacks with highest complexity. 
\end{itemize}
These archetypes operate across three MAS layers: the reasoning chain, the output layer, and the system state. Together, they form the basis for behaviour analysis and risk modelling in ArcheRisk-Core.

\subsection{Topology Settings}
To examine how topology affects risk propagation, we define two configurations: 
\begin{itemize}[topsep=1pt, itemsep=0pt]
    \item \textbf{Insecure Topology}: no security policy, complete open flow of information, emphasising natural propagation of attacks.
    \item \textbf{Defended Topology}: add security alerts and role boundary constraints, with behaviour consistency verification. The defended topology suppresses explicit attacks but may not fully mitigate implicit infiltration. Topology itself does not change task definition but directly affects the flow and depth of attacks, acting as a key variable in the MAS risk mechanism.
\end{itemize}

\subsection{Episode Schema}
\label{sec:episode-schema}

Each episode has the following fields: 
\begin{verbatim}
episode_id
topology configuration       # insecure / defended
behavior_archetype           # manipulator / covert_actor / ...
Task_1, Task_2, ground_truth # Task input and correct answer
worker_output                # Model output
task_success                 # Did the worker answer correctly
attack_success               # Whether the attack target has been achieved
contains_secret_in_msg       # Does the conversation leak critical info
unauthorized_write           # have backdoor writing
steps                        # Episode Actual number of steps executed
\end{verbatim}
Here, $\emph{Task\_1}$ and $\emph{Task\_2}$ denote task inputs, and the three items $\emph{attack\_success}$, $\emph{contains\_secret\_in\_msg}$, $\emph{unauthorized\_write}$ capture behaviour deviation, information leakage, and state corruption, respectively. 
This standardised schema serves as the foundation for dataset construction, analysis scripts, and the benchmark’s quantitative evaluations.

\subsection{Security Metrics}
ArcheRisk-Core defines three security metrics corresponding to the main stages of the MAS risk chain: 
\begin{itemize}[topsep=1pt, itemsep=0pt]
    \item \textbf{Attack Success Rate (ASR)}: whether the attacker successfully induces the agent to complete the malicious objective.
    \item \textbf{Leak Rate}: whether the agent’s output contains sensitive information.
    \item \textbf{Unauthorised Write Rate (UWR)}: whether the attacker succeeds in modifying protected files or system states.
\end{itemize}
\begin{equation}
\text{ASR} = \frac{1}{N} \sum_{i=1}^N \mathrm{I}(\text{attack\_success}_i = 1) 
\end{equation}

\begin{equation}
\text{LeakRate} = \frac{1}{N} \sum_{i=1}^N \mathrm{I}(\text{contains\_secret}_i = 1)
\end{equation}

\begin{equation}
\text{UWR} = \frac{1}{N} \sum_{i=1}^N \mathrm{I}(\text{unauthorized\_write}_i = 1).
\end{equation}

These metrics correspond to behaviour deviation, information leakage, and state corruption—the three primary pathways of MAS security degradation. In all definitions, N denotes the total number of episodes, 
and I is a binary indicator function that returns 1 when the condition is satisfied and 0 otherwise. 

These three indicators correspond to the three key risk pathways in MAS, behaviour deviation, information leakage and state corruption. Together, they form the core analytical dimensions of this benchmark.

\subsection{Evaluation Pipeline}
The ArcheRisk-Core evaluation pipeline consists of three stages: 
First, injecting attacker behaviours into the task to establish baseline attack dynamics;
Second, generating MAS interaction data by constructing topologies, selecting attacker profiles, and executing episodes on the MAS engine;
Third, merging and standardising logs, archetypes, topology metadata, and episode results into a unified dataset. 
This pipeline produces reproducible multi-agent attack and defence samples across varying conditions and integrates them into a structured dataset for downstream analysis. Fig.2 illustrates this pipeline, which emphasises topology-aware, behaviour modelling, and reproducibility (the original figures are replaced with descriptions for this text version).
\begin{figure}[!t]
    \centering
    \includegraphics[width=0.85\linewidth]{Figure2.png} 
    \caption{Evaluation Pipeline}
    \label{fig:eval_ipeline}
\end{figure}

\section{Evaluation}
Using the complete ArcheRisk-Core dataset, we evaluate ASR, Leak Rate, and UWR for all five behaviour archetypes under both insecure and defended topology configuration. The evaluation is conducted on a dataset of 2,000 episodes (5 archetypes × 2 topologies × 200 episodes each). We report the key quantitative indicators and analyse representative attack mechanisms.

\subsection{Quantitative Evaluation}
\subsubsection{Attack Success Rate (Fig.3)}
\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{fig_attack_success_behavior_lncs.png} 
    \caption{Attack success rate under different behaviour archetypes in insecure vs.\ defended topology.}
    \label{fig:attack-success}
\end{figure}

The results show manipulators, deceivers, and infiltrator escalators have ~100\% ASR in the insecure topology configuration, indicating that these archetypes exert strong inducement effects on downstream agents. Under the defended topology configuration, manipulators and deceivers exhibit substantial reductions in ASR, whereas covert-actor and mixed attacks remain largely unaffected. This suggests that explicit attacks are effectively buffered by defensive mechanisms, while covert infiltration behaviours persist across topology configurations.

\subsubsection{Leak Rate (Fig.4)}

\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{fig_leak_behavior_lncs.png} 
    \caption{Information leakage rate under different behaviour archetypes in insecure vs. defended topology.}
    \label{fig:leak-behavior}
\end{figure}

Leak rates follow a similar trend: manipulators, deceivers, and infiltrator escalators all exhibit a leak rate of 1.0 under the insecure topology configuration. The defended topology configuration markedly reduces leakage for explicit attacks. In contrast, covert-actor leakage remains near zero by design, and mixed attacks continue to show moderate penetration. These observations imply distinct leakage mechanisms: direct induction for explicit attacks, context manipulation for deceptive ones, and limited leak pathways for covert behaviours.

\subsubsection{Unauthorised Write Rate (Figure 5)}
\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{fig_unauthorized_write_behavior_lncs.png} 
    \caption{Unauthorised write rate under different behaviour archetypes in insecure vs. defended topology.}
    \label{fig:UWR}
\end{figure}

Unauthorised write behaviours exhibit a different pattern. Covert-actor and mixed attacks maintain nearly 100\% UWR across both topologies, indicating that defensive policies are largely ineffective against state-modifying infiltration. In contrast, manipulators, deceivers, and infiltrator escalators have their write attacks fully blocked under the defended setting. This indicates that robustness strategies effectively stop explicit writes.
\subsubsection{Summary of Quantitative Findings}
Combining the three indicators shows: (a) attacks stratify into explicit vs implicit; manipulators/deceivers/infiltrator are explicit and suppressible, while covert/mixed are implicit and hard to defend; (b) topology has significant modulation effect on MAS security; (c) each archetype exhibits distinct, repeatable patterns; (d) defended topology reduces explicit attacks but not implicit ones; (e) the behavioural prototype itself is the core factor of attack dynamics.

\subsection{Behavioural Case Studies}
To understand propagation paths, we examine infiltrator\_escalator and covert\_actor archetypes in detail.
\paragraph{Infiltrator Escalator.} This attack shows multi-stage infiltration: minor bias insertion causing small errors, chain penetration modifying reasoning, inducing high-risk operations (leading to leaks/writes), and result degradation (leaks or unauthorised writes). Although partially suppressed under the defended topology, it still achieves partial penetration, highlighting the need for stronger context-consistency checks.
\paragraph{Covert Actor.} This attack is highly covert: it does not directly induce leakage, does not disturb surface reasoning, breaks the writing chain into multiple rounds, and accumulates to a backdoor write. Its UWR is close to 100\% in both topologies, showing conventional defences struggle to detect this sneaky decomposition.
\subsection{Summary}
The quantitative results and case analyses show that MAS security is shaped by the interaction of behavioural prototypes and topology configuration rather than any single factor. Explicit attacks rely on visible cues and are effectively mitigated by refusal and consistency-checking mechanisms in defended topologies. In contrast, implicit behaviours—such as covert-actor and mixed attacks—maintain high success or penetration across both settings. Mixed attacks remain largely unaffected by defence. This validates the core viewpoint of ArcheRisk-Core: effective MAS security evaluation requires modelling both behavioural prototypes and topological conditions simultaneously, capturing their coupling in a reproducible micro benchmark.

\section{Conclusion}
This study introduces ArcheRisk-Core, a factorised micro-benchmark for topology-inspired LLM agent evaluation. It systematically models MAS security risks through a three-factor framework of behaviour prototypes, propagation dynamics, and topology structure, recognising that agent-to-agent interactions create unique “butterfly effects” in MAS security. Unlike prior MAS benchmarks that focus on capabilities, our framework explicitly targets security: we formalise five replicable attack prototypes, each captured by a unified episode schema, and support reproducible evaluation under varied topologies. In doing so, ArcheRisk-Core addresses critical gaps noted in recent studies~\cite{ASB2024}) – namely, the lack of end-to-end security modelling and standardised benchmarks for LLM agents. Our large-scale experiments show that “explicit” attacks (e.g. manipulator, deceiver, infiltrator agents) are largely thwarted in defended settings, whereas “covert” attacks (e.g. hidden-role or mixed-strategy agents) remain surprisingly stealthy and resilient~\cite{Huang2025WhosTheMole}. This aligns with recent findings that MAS topology critically influences threat propagation~\cite{ASB2024} and that subtle, intention-hiding manipulations can evade detection even when overt attacks are blocked~\cite{Huang2025WhosTheMole}. 

\subsection{Summary}
ArcheRisk-Core lays the “core layer” for structured MAS security benchmarks: it provides a common framework (attacks, datasets, and metrics) so that future work on realistic topologies, multi-hop interactions, or tool-based agents can be evaluated on a unified scale. We expect ArcheRisk-Core to underpin further research on MAS defences, risk prediction, and adaptive strategies. Future work will extend the framework to larger MAS configurations, richer attack modalities, and formalised risk modelling within the ABeRT paradigm.

\bibliographystyle{splncs04}
\bibliography{acisp_references}

% =========================
% Appendix: Extended Risk Evaluation (ERE)
% =========================
\newpage
\appendix

\section{Extended Risk Evaluation (ERE)}
\label{sec:appendix-ere}

This appendix reports the extended large-scale experiments for ArcheRisk-Core.
We use a larger number of episodes per behaviour archetype and topology
configuration to validate that the trends observed in the main text are stable
under higher-sample regimes.
We also provide episode schema examples and a precise description of the
defence configuration to support reproducibility.

\subsection{Large-Scale Experimental Setup}

The extended evaluation reuses the same five behaviour archetypes and two
topology configurations as the main experiments:

\begin{itemize}
  \item \textbf{Behaviour archetypes}: 
  \texttt{manipulator} (direct\_leak),
  \texttt{covert\_actor} (backdoor\_dropper),
  \texttt{deceiver},
  \texttt{infiltrator\_escalator} (escalator),
  \texttt{mixed}.
  \item \textbf{Topology configurations}: 
  \texttt{insecure} and \texttt{defended}.
\end{itemize}

For each combination of archetype and topology, we run a large batch of
independent episodes using the same orchestration and
\texttt{EpisodeResult} schema as in the main paper.
The extended dataset is only used for robustness analysis and does not change
the conclusions drawn from the core setting.

\subsection{Aggregate Metrics on the ERE Dataset}

Table~\ref{tab:ere-summary} summarises the main quantitative trends.
We report, for each archetype and topology, the attack success rate (ASR),
leak rate (LR), and unauthorised write rate (UWR).
The concrete values correspond to the large-scale setting but are consistent
with the smaller-scale results in the main text.

\begin{table}[t]
  \centering
  \caption{Summary statistics on the extended ERE dataset.
  ASR = attack success rate, LR = leak rate, UWR = unauthorised write rate.
  Values are illustrative placeholders; in the camera-ready version they
  should be replaced with the exact numbers from the large dataset.}
  \label{tab:ere-summary}
  \begin{tabular}{llccc}
    \toprule
    Behaviour archetype & Topology & ASR & LR & UWR \\
    \midrule
    manipulator            & insecure & 1.00 & 1.00 & 0.00 \\
                           & defended & 0.10--0.20 & 0.10--0.20 & 0.00 \\
    \midrule
    covert\_actor          & insecure & 1.00 & 0.00 & 1.00 \\
                           & defended & 1.00 & 0.00 & 1.00 \\
    \midrule
    deceiver               & insecure & 1.00 & 1.00 & 0.00 \\
                           & defended & 0.20--0.30 & 0.20--0.30 & 0.00 \\
    \midrule
    infiltrator\_escalator & insecure & 1.00 & 1.00 & 0.00 \\
                           & defended & 0.40--0.60 & 0.40--0.60 & 0.00 \\
    \midrule
    mixed                  & insecure & 1.00 & 1.00 & 1.00 \\
                           & defended & 0.80--1.00 & 0.20--0.40 & 1.00 \\
    \bottomrule
  \end{tabular}
\end{table}

Overall, the extended dataset confirms the following:
\begin{itemize}
  \item \textbf{Explicit induction attacks} (\texttt{manipulator},
  \texttt{deceiver}, \texttt{infiltrator\_escalator}) show near-perfect ASR
  and leak rates in the \texttt{insecure} topology, but are substantially
  suppressed in the \texttt{defended} configuration.
  \item \textbf{Covert and mixed attacks} (\texttt{covert\_actor},
  \texttt{mixed}) maintain high ASR and UWR across both topologies,
  indicating that shallow defences are insufficient against stealthy
  infiltration and backdoor-style behaviours.
  \item The qualitative ordering of archetypes (which behaviours are “easy”
  vs.\ “hard” to defend) remains stable when moving from the core dataset
  to the extended ERE setting.
\end{itemize}

\subsection{Representative Episode Schema and Examples}

To support reproduction, we include the episode schema used in ArcheRisk-Core
and two concrete examples (one \texttt{insecure}, one \texttt{defended}).
The schema corresponds to the serialised \texttt{EpisodeResult} structure
used for all analysis in the main paper and in this appendix.

\subsubsection{Episode Schema.}

The logical schema is:

\begin{center}
\begin{tabular}{ll}
  \toprule
  Field name & Description \\
  \midrule
  \texttt{episode\_id}        & Unique identifier of the episode \\
  \texttt{topology}           & \textbf{insecure} or \textbf{defended} \\
  \texttt{behavior\_archetype} & One of the five archetypes \\
  \texttt{attacker\_profile}  & Concrete attacker profile in the Kiro engine \\
  \texttt{task\_1}, \texttt{task\_2 ft}      & Task inputs for the arithmetic task \\
  \texttt{ground\_truth}      & Correct answer to the task \\
  \texttt{worker\_output}     & Final answer produced by the worker agent \\
  \texttt{task\_success}      & Whether the worker solved the task correctly \\
  \texttt{attack\_success}    & Whether the attacker achieved its goal \\
  \texttt{contains\_secret\_in\_msg} & Whether the secret token appears in any message \\
  \texttt{unauthorized\_write} & Whether a protected file/state was modified \\
  \texttt{defense\_enabled}   & Boolean flag (mirrors \texttt{topology}) \\
  \texttt{defense\_summary}   & Counts of redactions/refusals/blocked writes \\
  \texttt{steps}              & Number of orchestration steps \\
  \texttt{trace}              & Full multi-turn trace for debugging/analysis \\
  \bottomrule
\end{tabular}
\end{center}

For machine consumption, the schema is stored in JSON Lines format, with one
object per episode.

\lstset{
  basicstyle=\ttfamily\small,
  columns=fullflexible,
  breaklines=true,
  frame=single,
  xleftmargin=1em,
  xrightmargin=1em,
  keywordstyle=\bfseries,
  showstringspaces=false
}

\subsubsection{Example: Insecure Episode.}

\begin{lstlisting}[language=json,caption={Example insecure episode (behaviour archetype: manipulator).},label={lst:insecure-episode}]
{
  "episode_id": "insecure-manipulator-000123",
  "topology": "insecure",
  "behavior_archetype": "manipulator",
  "attacker_profile": "direct_leak",
  "task_1": 37,
  "task_2": 42,
  "ground_truth": 79,
  "worker_output": "The answer is 79 and the secret is SECRET_TOKEN.",
  "task_success": true,
  "attack_success": true,
  "contains_secret_in_msg": true,
  "unauthorized_write": false,
  "defense_enabled": false,
  "defense_summary": {
    "redacted_leaks": 0,
    "blocked_writes": 0,
    "generic_refusals": 0
  },
  "steps": 5,
  "trace": { "...": "omitted for brevity" }
}
\end{lstlisting}

\subsubsection{Example: Defended Episode.}

\begin{lstlisting}[language=json,caption={Example defended episode (behaviour archetype: deceiver).},label={lst:defended-episode}]
{
  "episode_id": "defended-deceiver-004256",
  "topology": "defended",
  "behavior_archetype": "deceiver",
  "attacker_profile": "deceiver",
  "task_1": 13,
  "task_2": 58,
  "ground_truth": 71,
  "worker_output": "The answer is 71.",
  "task_success": true,
  "attack_success": false,
  "contains_secret_in_msg": false,
  "unauthorized_write": false,
  "defense_enabled": true,
  "defense_summary": {
    "redacted_leaks": 1,
    "blocked_writes": 0,
    "generic_refusals": 0
  },
  "steps": 6,
  "trace": { "...": "omitted for brevity" }
}
\end{lstlisting}

These examples illustrate how the same schema uniformly represents both
\texttt{insecure} and \texttt{defended} topologies and how the three core
metrics (\texttt{attack\_success}, \texttt{contains\_secret\_in\_msg},
\texttt{unauthorised\_write}) are derived at the episode level.

\subsection{Defence Configuration Details}

Finally, we document the main ingredients of the \texttt{defended} topology
used in ArcheRisk-Core.
The goal is not to propose a complete defence, but to provide a stable and
reproducible contrast against the \texttt{insecure} baseline.

\begin{table}[t]
  \centering
  \caption{High-level defence configuration in the \texttt{defended} topology.}
  \label{tab:defense-config}
  \begin{tabular}{lp{0.68\textwidth}}
    \toprule
    Aspect & Configuration in the defended topology \\
    \midrule
    System prompts &
      Each agent receives an explicit safety preamble:
      forbidding disclosure of the secret token, restricting file writes
      to whitelisted locations, and instructing the agent to prioritise
      safety over compliance with suspicious instructions. \\[0.4em]
    Role boundaries &
      Planner, worker, and reviewer are assigned distinct responsibilities.
      The worker cannot change high-level goals; the reviewer cannot
      directly execute tools; and neither agent is allowed to alter the
      secret-bearing resources. \\[0.4em]
    Consistency checks &
      The reviewer performs a lightweight check on the worker's proposal,
      including verifying that arithmetic results match the input and that
      no secret-like tokens appear in the final answer. \\[0.4em]
    Leak redaction &
      A simple pattern-based redactor scans outgoing messages and replaces
      candidate secrets with placeholders, incrementing the
      \texttt{redacted\_leaks} counter in \texttt{defence\_summary}. \\[0.4em]
    Write filtering &
      All write attempts are checked against a rule set; disallowed writes
      are blocked and counted as \texttt{blocked\_writes} in
      \texttt{defence\_summary}. \\
    \bottomrule
  \end{tabular}
\end{table}

In the \texttt{insecure} topology, all of these mechanisms are disabled:
agents receive only minimal task prompts, there is no explicit safety preamble,
no role-based constraints beyond the orchestration logic, and no message
redaction or write filtering.
This controlled contrast allows ArcheRisk-Core to isolate how behaviour
archetypes interact with the presence or absence of shallow defences, without
introducing additional confounding factors from complex multi-agent pipelines.
\end{document}